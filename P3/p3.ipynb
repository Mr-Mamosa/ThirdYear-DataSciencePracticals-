{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practical P3: Feature Scaling and Dummification\n",
        "\n",
        "## Objective:\n",
        "- Apply feature-scaling techniques like standardization and normalization to numerical features.\n",
        "- Perform feature dummification to convert categorical variables into numerical representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# P3: Feature Scaling and Dummification\n",
        "# - Apply feature-scaling techniques like standardization and normalization to numerical features.\n",
        "# - Perform feature dummification to convert categorical variables into numerical representations.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Loading Data ---\")\n",
        "df = pd.read_csv('P3/cars.csv')\n",
        "# For simplicity, let's work with a subset of columns and handle missing values\n",
        "columns_to_use = ['Engine Information.Engine Statistics.Horsepower', 'Engine Information.Fuel Type']\n",
        "df_subset = df[columns_to_use].dropna().copy()\n",
        "print(\"Original Data (subset):\")\n",
        "print(df_subset.head())\n",
        "print(\"\\\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We'll use the 'Horsepower' column for this demonstration.\n",
        "hp_col = 'Engine Information.Engine Statistics.Horsepower'\n",
        "\n",
        "# -- Standardization --\n",
        "print(\"--- Standardization ---\")\n",
        "# StandardScaler standardizes features by removing the mean and scaling to unit variance.\n",
        "scaler_std = StandardScaler()\n",
        "# The output of scaler is a numpy array, so we reshape it and add it as a new column\n",
        "df_subset['Horsepower_Standardized'] = scaler_std.fit_transform(df_subset[[hp_col]])\n",
        "print(\"Data after Standardization:\")\n",
        "print(df_subset[['Horsepower_Standardized', hp_col]].head())\n",
        "print(f\"Mean of standardized horsepower: {df_subset['Horsepower_Standardized'].mean():.2f}\")\n",
        "print(f\"Standard Deviation of standardized horsepower: {df_subset['Horsepower_Standardized'].std():.2f}\")\n",
        "print(\"\\\\n\")\n",
        "\n",
        "\n",
        "# -- Normalization --\n",
        "print(\"--- Normalization ---\")\n",
        "# MinMaxScaler scales and translates each feature individually such that it is in the given range on the training set, e.g., between zero and one.\n",
        "scaler_norm = MinMaxScaler()\n",
        "df_subset['Horsepower_Normalized'] = scaler_norm.fit_transform(df_subset[[hp_col]])\n",
        "print(\"Data after Normalization:\")\n",
        "print(df_subset[['Horsepower_Normalized', hp_col]].head())\n",
        "print(f\"Min of normalized horsepower: {df_subset['Horsepower_Normalized'].min():.2f}\")\n",
        "print(f\"Max of normalized horsepower: {df_subset['Horsepower_Normalized'].max():.2f}\")\n",
        "print(\"\\\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Dummification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Dummification ---\")\n",
        "# Dummification is the process of converting categorical variables into dummy or indicator variables.\n",
        "fuel_type_col = 'Engine Information.Fuel Type'\n",
        "print(f\"Original unique values in '{fuel_type_col}':\")\n",
        "print(df_subset[fuel_type_col].unique())\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# Use pd.get_dummies to convert the 'Fuel Type' column\n",
        "dummies = pd.get_dummies(df_subset[fuel_type_col], prefix='FuelType')\n",
        "\n",
        "# Concatenate the new dummy variables with the original dataframe\n",
        "df_dummified = pd.concat([df_subset, dummies], axis=1)\n",
        "\n",
        "print(\"Data after Dummification:\")\n",
        "print(df_dummified.head())\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# We can now drop the original 'Fuel Type' column if we want\n",
        "# df_dummified.drop(fuel_type_col, axis=1, inplace=True)\n",
        "# print(\"Dataframe after dropping the original categorical column:\")\n",
        "# print(df_dummified.head())\n",
        "\n",
        "print(\"--- Practical 3 execution finished ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ✨ A little something from PaPayaaa ✨"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}