{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Practical P2: Data Frames and Basic Data Pre-processing\n",
        "\n",
        "## Objective:\n",
        "- Read data from CSV and JSON files into a data frame.\n",
        "- Perform basic data pre-processing tasks such as handling missing values and outliers.\n",
        "- Manipulate and transform data using functions like filtering, sorting, and grouping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# P2: Data Frames and Basic Data Pre-processing\n",
        "# - Read data from CSV and JSON files into a data frame.\n",
        "# - Perform basic data pre-processing tasks such as handling missing values and outliers.\n",
        "# - Manipulate and transform data using functions like filtering, sorting, and grouping.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Read data from CSV and JSON files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read from CSV\n",
        "print(\"--- Reading from CSV ---\")\n",
        "csv_file_path = 'P2/cars.csv'\n",
        "df_csv = pd.read_csv(csv_file_path)\n",
        "print(\"First 5 rows of the CSV data:\")\n",
        "print(df_csv.head())\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# Read from JSON\n",
        "print(\"--- Reading from JSON ---\")\n",
        "json_file_path = 'P2/dummy.json'\n",
        "df_json = pd.read_json(json_file_path)\n",
        "print(\"Data from the JSON file:\")\n",
        "print(df_json)\n",
        "print(\"\\\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Handling Missing Values ---\")\n",
        "# Create a copy to keep the original dataframe intact\n",
        "df = df_csv.copy()\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values before handling:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# For simplicity, we'll focus on a few columns. Let's look at 'Engine Information.Engine Statistics.Horsepower'.\n",
        "# It has missing values. Let's fill them with the mean.\n",
        "horsepower_col = 'Engine Information.Engine Statistics.Horsepower'\n",
        "if horsepower_col in df.columns:\n",
        "    mean_hp = df[horsepower_col].mean()\n",
        "    df[horsepower_col].fillna(mean_hp, inplace=True)\n",
        "    print(f\"Filled missing values in '{horsepower_col}' with the mean ({mean_hp:.2f}).\")\n",
        "else:\n",
        "    print(f\"Column '{horsepower_col}' not found. Skipping missing value handling for it.\")\n",
        "\n",
        "# Let's check another column, for example, 'Engine Information.Fuel Type'.\n",
        "# If it has missing values, we can fill with the mode.\n",
        "fuel_type_col = 'Engine Information.Fuel Type'\n",
        "if fuel_type_col in df.columns and df[fuel_type_col].isnull().any():\n",
        "    mode_fuel = df[fuel_type_col].mode()[0]\n",
        "    df[fuel_type_col].fillna(mode_fuel, inplace=True)\n",
        "    print(f\"Filled missing values in '{fuel_type_col}' with the mode ('{mode_fuel}').\")\n",
        "\n",
        "# Alternatively, we could drop rows with any missing values\n",
        "# df.dropna(inplace=True)\n",
        "# print(\"Dropped rows with missing values.\")\n",
        "\n",
        "print(\"\\\\nMissing values after handling:\")\n",
        "print(df[horsepower_col].isnull().sum())\n",
        "print(\"\\\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Handle Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Handling Outliers ---\")\n",
        "# We'll use the 'Identification.Year' column for this demonstration.\n",
        "year_col = 'Identification.Year'\n",
        "\n",
        "if year_col in df.columns:\n",
        "    Q1 = df[year_col].quantile(0.25)\n",
        "    Q3 = df[year_col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    print(f\"For '{year_col}':\")\n",
        "    print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
        "    print(f\"Lower bound for outliers: {lower_bound}\")\n",
        "    print(f\"Upper bound for outliers: {upper_bound}\")\n",
        "\n",
        "    # Find outliers\n",
        "    outliers = df[(df[year_col] < lower_bound) | (df[year_col] > upper_bound)]\n",
        "    print(f\"\\\\nNumber of outliers detected in '{year_col}': {len(outliers)}\")\n",
        "\n",
        "    # Handling outliers by capping them\n",
        "    df[year_col] = np.where(df[year_col] < lower_bound, lower_bound, df[year_col])\n",
        "    df[year_col] = np.where(df[year_col] > upper_bound, upper_bound, df[year_col])\n",
        "\n",
        "    print(\"Outliers have been capped to the lower and upper bounds.\")\n",
        "    print(f\"Min year after capping: {df[year_col].min()}\")\n",
        "    print(f\"Max year after capping: {df[year_col].max()}\")\n",
        "    print(\"\\\\n\")\n",
        "else:\n",
        "    print(f\"Column '{year_col}' not found. Skipping outlier handling.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Data Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Data Manipulation ---\")\n",
        "\n",
        "# Filtering data\n",
        "print(\"Filtering: Cars with more than 4 cylinders\")\n",
        "cylinders_col = 'Engine Information.Engine Statistics.Cylinders'\n",
        "if cylinders_col in df.columns:\n",
        "    high_cylinder_cars = df[df[cylinders_col] > 4]\n",
        "    print(high_cylinder_cars[['Identification.Make', cylinders_col]].head())\n",
        "else:\n",
        "    print(f\"Column '{cylinders_col}' not found. Skipping filtering.\")\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# Sorting data\n",
        "print(\"Sorting: Cars sorted by year (descending)\")\n",
        "sorted_cars = df.sort_values(by=year_col, ascending=False)\n",
        "print(sorted_cars[['Identification.Make', year_col]].head())\n",
        "print(\"\\\\n\")\n",
        "\n",
        "# Grouping data\n",
        "print(\"Grouping: Average horsepower by car make\")\n",
        "if horsepower_col in df.columns and 'Identification.Make' in df.columns:\n",
        "    avg_hp_by_make = df.groupby('Identification.Make')[horsepower_col].mean().reset_index()\n",
        "    avg_hp_by_make.columns = ['Make', 'Average Horsepower']\n",
        "    print(avg_hp_by_make.head())\n",
        "else:\n",
        "    print(\"Required columns for grouping not found. Skipping.\")\n",
        "\n",
        "print(\"\\\\n--- Practical 2 execution finished ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ✨ A little something from PaPayaaa ✨"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}